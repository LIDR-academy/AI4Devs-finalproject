---
description: Comprehensive testing approach integrating TDD+BDD practices with vertical slice development and ideation methodology
alwaysApply: false
---
# Core Principles

**Testing is NOT an afterthought**, it's integrated into every vertical slice from ideation to delivery. Every feature must have comprehensive test coverage before implementation.

**CRITICAL**: **No test should ever be left red**. All tests must pass before considering any change complete.

# Validation of Work - Test Execution Order

## Mandatory Test Validation
**Every change requires validation through relevant tests in this specific order, based on what has been changed:**

1. **Unit Tests** - Validate individual components work correctly
2. **Integration Tests** - Validate components work together with real dependencies
3. **E2E Tests** - Validate complete user workflows end-to-end

## What to Run During Development
- **Don't run all tests** - only run tests relevant to your current change
- **CI will handle full test suite** to catch any eventual breakage
- **Focus on relevant tests** to validate your specific implementation

## Test Execution Commands for Development

```bash
# Run only relevant integration tests  
npm run test:integration -- --testPathPattern="path/to/your/feature"

# Run only relevant E2E tests
npm run test:e2e -- --grep="your specific test pattern"

# For comprehensive validation (run all relevant tests in order)
npm run test:validate:feature --feature="your-feature-name"
```

# Testing Strategy Hierarchy

## 1. E2E Tests (Highest Priority for Happy Flows)
- **Location**: `/test/e2e/tests/` at project root
- **Scope**: Complete user workflows, UI interactions, happy flow variations
- **Database**: Real PostgreSQL in Docker containers
- **Coverage**: Happy flows + smoke tests crawling through app pages
- **Execution**: Against Docker containers, < 2min per test
- **Why**: Happy flow variations should be tested E2E by default, except when integration is costly/unreliable
- **Exception**: Use integration tests when external services are expensive, unreliable, or when mocking is necessary

## 2. Integration Tests (For Costly/Unreliable Scenarios)
- **Location**: `/test/integration/tests/` at project root
- **Scope**: Full user journey testing for specific activity/variation
- **Database**: Real PostgreSQL in Docker containers
- **Coverage**: Happy flows (when E2E is not suitable) + unhappy flows (mocking when necessary)
- **Execution**: Against Docker containers, < 30s per test
- **Why**: Use when E2E tests are not suitable due to costly/unreliable integrations
- **When to use**: External services that are expensive, unreliable, or require complex mocking

## 3. Contract Tests (Frontend API Integration)
- **Location**: `/frontend/src/services/api/(sub-api)`
- **Scope**: Frontend integration with ai4devs-api-client
- **Backend**: Mocked server responses
- **Coverage**: API contract validation, error handling, data transformation
- **Execution**: Fast, < 10s per test
- **Why**: Validate frontend-API integration without full backend dependency
- **When to use**: Test API client integration, error scenarios, and data contracts
- **Organization**: Each operation (fetch, create, edit, delete) has its own test file for better maintainability inside the sub-api folder

## 4. Unit Tests (Lowest Priority)
- **Location**: Close to code in each submodule
- **Scope**: Single function/class testing
- **Database**: Mocked
- **Coverage**: Individual component behavior and edge cases
- **Why**: For complementing code that integration and E2E could not cover

# Test Organization Structure

Follow the capability/feature/activity/variation hierarchy:

```
test/
├── tests/
│   ├── capability-name/
│   │   ├── feature-name/
│   │   │   └── activity-name/
│   │   │       ├── 1-activity-name.e2e.spec.ts
│   │   │       ├── 2-some-variation.e2e.spec.ts
│   │   │       ├── 3-costly-integration.int.spec.ts
│   │   │       └── 4-invalid-input.int.spec.ts
│   │   └── user-journeys/
│   │       ├── complete-budgeting-workflow.int.spec.ts
│   │       └── end-to-end-financial-tracking.int.spec.ts
```

# Test Naming Convention

- **Integration Tests**: `*.int.spec.ts`
- **E2E Tests**: `*.e2e.spec.ts`
- **Contract Tests**: `*.contract.spec.ts`
- **Unit Tests**: `*.spec.ts` (in submodules)

# Test Structure & BDD Implementation

```typescript
describe('Capability Name', () => {
  describe('Feature Name', () => {
    describe('Activity Name', () => {
      describe('Given [context]', () => {
        describe('When [action]', () => {
          describe('Then [expected result]', () => {
            it('happy flow variation', async () => {
              // Arrange: Setup test data using builders
              // Act: Execute the activity
              // Assert: Verify business outcomes
            });
          });
        });
      });
      describe('Given [slightly different context]', () => {
        describe('When [same action]', () => {
          describe('Then [other result]', () => {            
            it('unhappy flow variation', async () => {
              // Test error scenarios and edge cases
            });
            
            it('edge case variation', async () => {
              // Test boundary conditions
            });
          });
        });
      });
    });
  });
});
```

**Note**: Happy flow variations should be E2E tests default. Use integration tests only when:

- External services are expensive or unreliable
- Complex mocking is required
- E2E tests would be too slow or flaky

**Note**: A happy flow test should be named after the variation, not "happy flow"

# Test Data Management

## Use Test Builders
- **Location**: `/test/builders/`
- **Purpose**: Create consistent, realistic test data based on the business rules and contexts
- **Pattern**: Fluent builder methods returning `this`
- **Example**:
```typescript
const transaction = new TransactionBuilder()
  .asIncome()
  .withDescription('Salary')
  .onDate(new Date())
  .create();
```

## Data Cleanup
- Reset database state between test runs
- Use database transactions for test isolation
- Ensure business data consistency

# Vertical Slice Testing Requirements

## Before Implementation
1. **Identify each test variations** based on task at hand
2. **Define acceptance criteria for each of them** in BDD style (Given/When/Then)
3. **Create test structure** following capability/feature/activity hierarchy
4. **Design test data** using appropriate builders
5. **Choose test type**: Happy flows → E2E tests, Costly integrations → Integration tests
6. **Regenerate API client** if backend controllers changed (run backend-publisher container)

## During Implementation
1. **Write tests first** (TDD approach)
2. **Implement minimal code** to pass tests
3. **Refactor** while maintaining test coverage, **until ALL tests pass**
    1. **Check** with me if we should continue refactoring, 
    and if so, what we should aim to
4. **Ensure business rules** are properly tested
4. **Validate work** by running relevant tests in unit → integration → e2e order
5. **Ensure business rules** are properly tested

## After Implementation
1. **Verify test coverage** > 80% backend, > 70% frontend
2. **Run relevant unit tests** first - all must pass
3. **Run relevant integration tests** - all must pass  
4. **Run relevant E2E tests** - all must pass
5. **Validate business outcomes** not just technical implementation
6. **Document test scenarios** for future reference

# Testing Guidelines

## Business-Focused Testing
- **Test business logic**, not implementation details
- **Cover business rules** defined in acceptance criteria
- **Validate user workflows** end-to-end
- **Test data integrity** and business constraints

## Bug Fix Testing Requirements
- **E2E Test First**: Every bug fix starts by adding an E2E test that reproduces the bug exactly as reported
- **Reproduce the Bug**: The E2E test must fail initially, demonstrating the bug exists
- **Test First Approach**: Write the failing E2E test before implementing any fix
- **Regression Prevention**: The E2E test ensures the bug won't return
- **Coverage**: Ensure the specific scenario that caused the bug is covered
- **Documentation**: Document the bug scenario in test comments for future reference
- **BUGS.md Update**: After test passes, update BUGS.md to mark the bug as resolved [x]
- **Test Verification**: Ensure the E2E test fails before the fix and passes after implementation
- **Validation Required**: Run relevant tests in unit → integration → e2e order to ensure fix is complete

## Multi-Activity User Journey Testing
- **Cross-Activity Flows**: Test complete user workflows spanning multiple activities
- **Integration Points**: Verify data consistency between different activities
- **State Management**: Test how system state changes across activity boundaries
- **Location**: Place in dedicated files under `capability-name/user-journeys/`
- **Naming**: Use descriptive names like `complete-budgeting-workflow.int.spec.ts`
- **Test Type**: Use integration tests (`.int.spec.ts`) for multi-activity flows
- **Scope**: Focus on critical user paths that involve multiple features working together
- **Why Integration**: Multi-activity flows are complex and benefit from real database state

## Error Handling
- **Happy path**: Core functionality works correctly, each activity must have one test covering its happy path
  - **Default**: Use E2E tests for happy flows
  - **Exception**: Use integration tests only when E2E would be costly/unreliable
- **Unhappy paths**: Error scenarios handled gracefully (use integration tests)
- **Edge cases**: Boundary conditions and unusual inputs, those can go to unit tests
- **Critical failures**: System remains stable under stress

## Performance & Reliability
- **Fast execution**: Integration < 30s, E2E < 2min
- **Consistent results**: Tests should be non-deterministic, using the builder correctly should be enough to create an illusion of tests being deterministic e.g. TransactionBuilder.asIncome method will randomly create positive amount for the transaction as the important part here is that the income is positive
- **Parallel execution**: Tests can run independently, use transactions to make sure that they don't interfere with each other
- **Docker management**: Clean up containers after test runs

# Cross-Functional Requirements Integration

## Security Testing
- **Authentication**: JWT validation and session management
- **Authorization**: Role-based access control
- **Data protection**: Sensitive data encryption and validation

## Performance Testing
- **API response time**: < 500ms for 95% of requests
- **Database performance**: Optimized queries with caching
- **Concurrent operations**: Multiple users simultaneously

## Accessibility Testing
- **WCAG 2.1 AA compliance**: Screen reader support
- **Keyboard navigation**: All functionality accessible
- **Mobile responsiveness**: Touch-friendly interface

# Test Execution Commands

```bash
# Start Docker test environment
npm run test:docker:up

# IMPORTANT: After Backend Controller Changes
# Run backend-publisher container to regenerate API client code
# This is REQUIRED before running integration/E2E tests
docker-compose up backend-publisher

# Run relevant tests in proper order (development workflow)
npm run test:validate:feature --feature="feature-name"

# Run E2E tests first (happy flows)
npm run test:e2e

# Run integration tests (costly/unreliable scenarios)
npm run test:integration

# Run with coverage
npm run test:coverage

# Clean up
npm run test:docker:down
```

# Quality Gates

## Before Marking Any Change Complete
1. **All relevant unit tests pass** ✅
2. **All relevant integration tests pass** ✅  
3. **All relevant E2E tests pass** ✅
4. **No red tests remain** - this is non-negotiable
5. **Business logic validated** through test outcomes
6. **Code coverage meets requirements** (>80% backend, >70% frontend)

## Red Test Policy
- **Red tests block completion** - fix them before proceeding
- **Red tests indicate incomplete work** - don't commit with failing tests
- **Red tests require immediate attention** - they represent broken functionality
- **CI will catch red tests** but local validation is mandatory

## Troubleshooting Service Dependencies

When encountering errors, **always check the service dependency order** using the docker compose file as a reference:

### Service Dependency Chain (Example)

```
Frontend → Backend → Database
```

Each service also depends indirecly on Docker or the dev's local environment.

### Example: Frontend Failing to Fetch Data

If the frontend is failing to fetch data, the issue might be on:

1. **Frontend** such as network issue, API endpoint, etc, check first **Backend**'s logs to see if the problem's root cause is FE or BE
2. In case the problem originated on the FE's dependency, we know **Backend** might be having its own errors or a dependency might be failing. The **Database** is a BE's dependency, so we might check there for the problem's root cause.
3. If **Database** has an issue, we might need to understand if it's a service problem or environmental problem.

### Troubleshooting Steps

1. **Check docker-compose.yml** to understand service dependencies
2. **Start from the service where error happens** and move up the dependency chain reading each log to understand where the problem begins.
  - If log is not available like for FE, move up the dependency chain direcly
3. **Verify each layer** independently before moving up the chain

### Common Dependency Issues
- **Database down** → Backend fails → Frontend shows errors
- **Backend API errors** → Frontend receives error responses
- **Network connectivity** → Services can't communicate
- **Resource constraints** → Services crash or become unresponsive
- **Outdated API client** → Integration/E2E tests fail after backend controllers/endpoints change (we need to run the backend-publisher container)

# When to Apply This Rule

**ALWAYS** apply when:
- Creating new features or capabilities
- Implementing vertical slices
- Writing user stories
- Defining acceptance criteria
- Refactoring existing code
- Planning test coverage
- Defining acceptance criteria
- Refactoring existing code
- Validating any code changes
- Fixing bugs or issues
- Planning test coverage
