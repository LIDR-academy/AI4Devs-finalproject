# Story 1.3: Indexación Código Básica

## Status
Approved

## Story
**As a** developer que quiere respuestas sobre mi codebase específico,  
**I want** que el sistema tenga conocimiento del código actual,  
**so that** las respuestas sean relevantes a mi proyecto real

## Acceptance Criteria

1. Script manual indexa archivos .py, .js, .ts del proyecto local
2. Usa BGE-M3 embeddings via SageMaker endpoint básico
3. Almacena vectors en PostgreSQL + pgvector (single table MVP)
4. Indexa mínimo 80% de archivos core del codebase
5. Retrieval búsqueda devuelve top-5 resultados relevantes por query

## Tasks / Subtasks

### Database & Vector Storage Setup
- [ ] **Task 1: PostgreSQL + pgvector Database Setup** (AC: 3)
  - [ ] Instalar y configurar PostgreSQL 15+ con pgvector extension
  - [ ] Crear schema `knowledge_management` según arquitectura
  - [ ] Implementar tabla `embeddings` con vector(1024) para BGE-M3
  - [ ] Configurar HNSW index para vector similarity search
  - [ ] Setup database connection y migrations con Alembic

- [ ] **Task 2: Knowledge Management Data Models** (AC: 3)
  - [ ] Crear `src/infrastructure/database/models.py` con SQLAlchemy models
  - [ ] Implementar `Document` model con metadata tracking
  - [ ] Implementar `Embedding` model con pgvector integration
  - [ ] Configurar relationships y foreign keys
  - [ ] Setup domain separation para technical embeddings

### Code Indexing Script Implementation
- [ ] **Task 3: Manual Indexing Script Development** (AC: 1, 4)
  - [ ] Crear `scripts/index_codebase.py` command-line script
  - [ ] Implementar file discovery para .py, .js, .ts files
  - [ ] Configurar exclusions (.git, node_modules, __pycache__)
  - [ ] Implementar progress tracking y logging
  - [ ] Setup configurable target directory scanning

- [ ] **Task 4: Code Content Processing** (AC: 4)
  - [ ] Implementar text extraction con encoding detection
  - [ ] Configurar file filtering (minimum size, valid syntax)
  - [ ] Implementar chunking strategy para archivos largos
  - [ ] Setup metadata extraction (file path, language, size)
  - [ ] Configurar 80%+ coverage validation

### BGE-M3 SageMaker Integration
- [ ] **Task 5: AWS SageMaker Embeddings Service** (AC: 2)
  - [ ] Crear `src/infrastructure/llm/sagemaker_embeddings.py` 
  - [ ] Implementar SageMaker client para BGE-M3 endpoint
  - [ ] Configurar authentication y region setup (us-east-1)
  - [ ] Implementar batch processing para embeddings generation
  - [ ] Setup error handling y retry logic con exponential backoff

- [ ] **Task 6: Embeddings Generation Pipeline** (AC: 2)
  - [ ] Implementar text preprocessing para BGE-M3 format
  - [ ] Configurar batch size optimization (32-64 items per batch)
  - [ ] Implementar vector normalization y validation
  - [ ] Setup progress tracking para large codebases
  - [ ] Configurar cost monitoring y budget alerts

### Vector Search & Retrieval
- [ ] **Task 7: Semantic Search Implementation** (AC: 5)
  - [ ] Implementar `src/services/code_search_service.py`
  - [ ] Configurar pgvector cosine similarity search
  - [ ] Implementar query embedding generation
  - [ ] Setup similarity threshold tuning (default: 0.8)
  - [ ] Configurar top-5 results ranking con metadata

- [ ] **Task 8: Search Quality Validation** (AC: 5)
  - [ ] Implementar search accuracy metrics
  - [ ] Configurar relevance scoring validation
  - [ ] Setup test queries para different code patterns
  - [ ] Implementar search performance monitoring
  - [ ] Configurar quality thresholds y alerting

### Testing & Validation
- [ ] **Task 9: Comprehensive Testing Suite** (AC: All)
  - [ ] Crear `tests/integration/test_database/test_vector_search.py`
  - [ ] Implementar `tests/unit/test_services/test_code_search.py`
  - [ ] Setup test fixtures con sample code files
  - [ ] Configurar mocking para SageMaker endpoints
  - [ ] Implementar end-to-end indexing tests

## Sequence Diagram

```mermaid
sequenceDiagram
    participant Admin as Admin/Script
    participant CI as Codebase Indexer
    participant FS as File System
    participant SE as SageMaker Embeddings
    participant AWS as AWS SageMaker
    participant DB as PostgreSQL+pgvector
    participant CS as Code Search Service
    participant User as End User

    Note over Admin,User: Story 1.3 - Indexación Código Básica

    %% Manual Indexing Process
    Note over Admin,DB: Code Indexing Pipeline
    Admin->>+CI: python scripts/index_codebase.py ./src
    CI->>CI: initialize_indexer(target_directory)
    
    %% File Discovery Phase
    CI->>+FS: discover_files([.py, .js, .ts])
    FS->>FS: scan_directory(exclusions)
    FS-->>-CI: file_list[]
    CI->>CI: validate_80%_coverage()
    
    %% Content Processing Loop
    loop For Each Code File
        CI->>+FS: read_file_content(file_path)
        FS-->>-CI: file_content
        CI->>CI: extract_metadata(file_path, size, language)
        CI->>CI: apply_chunking_strategy()
        
        %% BGE-M3 Embedding Generation
        CI->>+SE: generate_embeddings(text_chunks[])
        SE->>SE: prepare_batch_request(batch_size=32)
        SE->>+AWS: invoke_endpoint(bge-m3-endpoint)
        Note over AWS: BGE-M3 Processing<br/>Target: <500ms
        AWS-->>-SE: embedding_vectors[]
        SE->>SE: normalize_vectors()
        SE-->>-CI: embeddings_1024d[]
        
        %% Database Storage
        CI->>+DB: store_document(metadata, content)
        DB-->>-CI: document_id
        CI->>+DB: store_embeddings(document_id, vectors)
        DB->>DB: create_hnsw_index()
        DB-->>-CI: storage_complete
        
        CI->>CI: update_progress_tracker()
    end
    
    CI-->>-Admin: indexing_complete(coverage: 85%)

    %% Search Quality Validation
    Note over CI,CS: Post-Indexing Validation
    CI->>+CS: validate_search_quality()
    CS->>+DB: test_semantic_search("authentication patterns")
    DB->>DB: execute_vector_similarity()
    DB-->>-CS: top_5_results[]
    CS->>CS: calculate_relevance_scores()
    CS-->>-CI: validation_passed

    %% Runtime Search Flow
    Note over CS,User: Code Search Usage
    User->>+CS: search_code("How to implement JWT auth?")
    CS->>+SE: generate_query_embedding(query)
    SE->>+AWS: invoke_endpoint(query_text)
    AWS-->>-SE: query_vector_1024d
    SE-->>-CS: normalized_query_embedding
    
    CS->>+DB: semantic_search(query_vector, threshold=0.8, limit=5)
    DB->>DB: execute_pgvector_cosine_search()
    DB-->>-CS: search_results[]
    
    CS->>CS: format_results_with_metadata()
    CS-->>-User: ranked_code_snippets[]

    %% Error Handling Flow
    Note over CI,AWS: Error Scenario - SageMaker Unavailable
    CI->>+SE: generate_embeddings(batch)
    SE->>+AWS: invoke_endpoint(bge-m3-endpoint)
    AWS-->>-SE: ServiceUnavailable Error
    SE->>SE: implement_retry_logic()
    SE->>SE: exponential_backoff(attempt=1)
    SE-->>-CI: EmbeddingGenerationError
    CI->>CI: log_failed_file()
    CI->>CI: continue_with_next_file()
```

## Dev Notes

### Architecture Context

**Database Foundation:** [Source: database-schema.md#vector-storage]
The system uses PostgreSQL 15+ with pgvector extension for vector storage, designed for scalability and performance:

```sql
-- Core extensions setup
CREATE EXTENSION IF NOT EXISTS "vector";
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Knowledge management schema
CREATE SCHEMA knowledge_management;

-- Documents table for source code files
CREATE TABLE knowledge_management.documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    knowledge_base_id UUID,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    content_hash VARCHAR(64) NOT NULL,
    domain VARCHAR(50) DEFAULT 'technical',
    content_type VARCHAR(100),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Embeddings table with pgvector support
CREATE TABLE knowledge_management.embeddings (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES knowledge_management.documents(id),
    domain VARCHAR(50) NOT NULL DEFAULT 'technical',
    embedding_model VARCHAR(100) NOT NULL,  -- 'BGE-M3-endpoint'
    embedding_vector vector(1024),  -- BGE-M3 dimension
    chunk_text TEXT NOT NULL,
    chunk_index INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Performance indexes for vector search
CREATE INDEX idx_embeddings_domain ON knowledge_management.embeddings(domain);
CREATE INDEX idx_embeddings_vector_cosine ON knowledge_management.embeddings 
    USING hnsw (embedding_vector vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);
```

**Vector Search Function:** [Source: database-schema.md#semantic-search]
```sql
-- Optimized semantic search function
CREATE OR REPLACE FUNCTION knowledge_management.semantic_search(
    query_vector vector(1024),
    search_domain text DEFAULT 'technical',
    similarity_threshold real DEFAULT 0.8,
    result_limit int DEFAULT 5
) RETURNS TABLE (
    document_id uuid,
    chunk_text text,
    similarity_score real,
    file_path text,
    content_type text
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.id as document_id,
        e.chunk_text,
        1 - (e.embedding_vector <=> query_vector) as similarity_score,
        d.title as file_path,
        d.content_type
    FROM knowledge_management.embeddings e
    JOIN knowledge_management.documents d ON e.document_id = d.id
    WHERE 
        e.domain = search_domain
        AND 1 - (e.embedding_vector <=> query_vector) >= similarity_threshold
    ORDER BY e.embedding_vector <=> query_vector ASC
    LIMIT result_limit;
END;
$$ LANGUAGE plpgsql;
```

### Previous Story Integration

**Story 1.1 & 1.2 Foundation:**
- **Nura Core Kernel**: Provides plugin registration system and FastAPI foundation for code search endpoints
- **Dev Agent Plugin**: Established AWS integration patterns and error handling that will be extended for SageMaker
- **Database Connection**: KernelContext provides database session management for vector storage
- **Logging Framework**: Structured logging system ready for indexing progress tracking

**Integration Points:**
- Code search service will integrate with DevAgent via kernel routing
- SageMaker client patterns follow AWS Bedrock integration from Story 1.2
- Database models extend the existing plugin data model patterns
- Error handling and retry logic consistent with established patterns

### BGE-M3 SageMaker Implementation

**SageMaker Endpoint Configuration:** [Source: component-diagrams.md#aws-sagemaker-plugin]
```python
# src/infrastructure/llm/sagemaker_embeddings.py
import boto3
import json
import numpy as np
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class BGEConfig:
    endpoint_name: str = "bge-m3-endpoint"
    region: str = "us-east-1"
    max_sequence_length: int = 8192
    batch_size: int = 32
    timeout_seconds: int = 60

class SageMakerEmbeddingsClient:
    def __init__(self, config: BGEConfig):
        self.config = config
        self.client = boto3.client('sagemaker-runtime', region_name=config.region)
        
    async def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate BGE-M3 embeddings via SageMaker endpoint"""
        embeddings = []
        
        # Process in batches for efficiency
        for i in range(0, len(texts), self.config.batch_size):
            batch = texts[i:i + self.config.batch_size]
            
            payload = {
                "inputs": batch,
                "parameters": {
                    "instruction": "",  # BGE-M3 specific
                    "max_length": self.config.max_sequence_length
                }
            }
            
            try:
                response = self.client.invoke_endpoint(
                    EndpointName=self.config.endpoint_name,
                    ContentType='application/json',
                    Body=json.dumps(payload)
                )
                
                result = json.loads(response['Body'].read().decode())
                batch_embeddings = result.get('embeddings', [])
                embeddings.extend(batch_embeddings)
                
            except Exception as e:
                logger.error(f"SageMaker embedding generation failed: {str(e)}")
                # Fallback to local embeddings or error handling
                raise EmbeddingGenerationError(f"BGE-M3 endpoint failed: {str(e)}")
        
        return embeddings
```

**Code Indexing Pipeline:** [Source: data-architecture.md#late-chunking-engine]
```python
# scripts/index_codebase.py
import os
import asyncio
from pathlib import Path
from typing import List, Dict, Any
import hashlib

class CodebaseIndexer:
    def __init__(self, target_directory: str):
        self.target_directory = Path(target_directory)
        self.supported_extensions = {'.py', '.js', '.ts', '.jsx', '.tsx'}
        self.exclude_patterns = {
            '__pycache__', 'node_modules', '.git', '.pytest_cache',
            'dist', 'build', '.next', '.nuxt'
        }
        
    async def index_codebase(self) -> Dict[str, Any]:
        """Main indexing workflow"""
        files_found = self._discover_files()
        
        indexed_count = 0
        total_files = len(files_found)
        
        for file_path in files_found:
            try:
                await self._process_file(file_path)
                indexed_count += 1
                
                # Progress tracking
                progress = (indexed_count / total_files) * 100
                logger.info(f"Indexing progress: {progress:.1f}% ({indexed_count}/{total_files})")
                
            except Exception as e:
                logger.warning(f"Failed to index {file_path}: {str(e)}")
        
        coverage = (indexed_count / total_files) * 100
        return {
            "files_found": total_files,
            "files_indexed": indexed_count,
            "coverage_percentage": coverage,
            "success": coverage >= 80.0  # AC requirement
        }
    
    def _discover_files(self) -> List[Path]:
        """Discover indexable code files"""
        files = []
        
        for root, dirs, filenames in os.walk(self.target_directory):
            # Filter excluded directories
            dirs[:] = [d for d in dirs if d not in self.exclude_patterns]
            
            for filename in filenames:
                file_path = Path(root) / filename
                if file_path.suffix in self.supported_extensions:
                    files.append(file_path)
        
        return files
```

### Vector Search Service Implementation

**Code Search Service:** [Source: data-architecture.md#contextual-retrieval]
```python
# src/services/code_search_service.py
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from .sagemaker_embeddings import SageMakerEmbeddingsClient

class CodeSearchService:
    def __init__(self, db_session: Session, embeddings_client: SageMakerEmbeddingsClient):
        self.db = db_session
        self.embeddings_client = embeddings_client
        
    async def search_code(
        self, 
        query: str, 
        similarity_threshold: float = 0.8,
        max_results: int = 5
    ) -> List[Dict[str, Any]]:
        """Search for relevant code using semantic similarity"""
        
        # Generate query embedding
        query_embeddings = await self.embeddings_client.generate_embeddings([query])
        query_vector = query_embeddings[0]
        
        # Execute semantic search using pgvector function
        search_results = self.db.execute(
            "SELECT * FROM knowledge_management.semantic_search(%s, %s, %s, %s)",
            (query_vector, 'technical', similarity_threshold, max_results)
        ).fetchall()
        
        # Format results for consumption
        formatted_results = []
        for result in search_results:
            formatted_results.append({
                "document_id": result.document_id,
                "file_path": result.file_path,
                "code_snippet": result.chunk_text,
                "similarity_score": float(result.similarity_score),
                "content_type": result.content_type
            })
        
        return formatted_results
```

### Testing Requirements

**Testing Framework:** [Source: testing-strategy.md#test-organization]
- **Unit Tests**: `tests/unit/test_services/test_code_search.py` for search service logic
- **Integration Tests**: `tests/integration/test_database/test_vector_search.py` for database operations
- **Mock Strategy**: Mock SageMaker endpoints for unit tests, use test database for integration
- **Coverage Target**: Minimum 80% code coverage for indexing and search components

**Test File Locations:**
```
tests/
├── unit/
│   ├── test_services/
│   │   └── test_code_search.py          # Code search service tests
│   └── test_infrastructure/
│       └── test_sagemaker_embeddings.py # BGE-M3 client tests
├── integration/
│   ├── test_database/
│   │   └── test_vector_search.py        # pgvector integration tests
│   └── test_external/
│       └── test_sagemaker_endpoint.py   # SageMaker endpoint tests
└── fixtures/
    ├── sample_code/                     # Test code files
    │   ├── sample.py
    │   ├── sample.js
    │   └── sample.ts
    └── embeddings_mocks.py             # Mock BGE-M3 responses
```

**Required Test Cases:**
- File discovery and filtering with exclusion patterns
- Code content processing and chunking
- BGE-M3 embedding generation with batch processing
- Vector storage and retrieval with similarity search
- Search quality validation with relevance scoring
- Error handling for SageMaker endpoint failures
- Performance testing for large codebase indexing

### Dependencies & Environment

**Python Dependencies (additional to Stories 1.1 & 1.2):**
```
sqlalchemy==2.0.23           # Database ORM for PostgreSQL
alembic==1.13.0              # Database migrations
psycopg2-binary==2.9.9       # PostgreSQL adapter
pgvector==0.2.4              # pgvector Python client
numpy==1.24.4                # Vector operations
boto3==1.34.0                # Already included from Story 1.2
aiofiles==23.2.0             # Async file operations
chardet==5.2.0               # Encoding detection
```

**Environment Variables:**
```
# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/nura_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=nura_db
POSTGRES_USER=nura_user
POSTGRES_PASSWORD=secure_password

# BGE-M3 SageMaker Configuration
SAGEMAKER_ENDPOINT_NAME=bge-m3-endpoint
AWS_DEFAULT_REGION=us-east-1
BGE_BATCH_SIZE=32
BGE_MAX_SEQUENCE_LENGTH=8192

# Indexing Configuration
INDEXING_TARGET_DIRECTORY=./
INDEXING_COVERAGE_THRESHOLD=80.0
```

**Database Setup Requirements:**
- PostgreSQL 15+ with pgvector extension installed
- Database user with CREATE and INSERT permissions
- Sufficient storage for vector embeddings (estimate 4KB per chunk)
- Memory configuration: work_mem ≥ 256MB for vector operations

**AWS Configuration Requirements:**
- SageMaker endpoint deployed with BGE-M3 model
- IAM permissions for sagemaker:InvokeEndpoint
- Regional availability: us-east-1 (primary)
- Cost monitoring: Budget alerts for embedding generation

### Integration with Existing System

**Kernel Integration Points:** [Source: backend-architecture.md#kernelmanager]
- Integration with existing FastAPI application for search endpoints
- Access to shared KernelContext for database session management
- Event-driven communication for indexing progress updates
- Shared logging framework for indexing and search operations
- Error handling patterns consistent with plugin architecture

**Plugin Architecture Extension:**
- Code search service extends existing service patterns from Stories 1.1 & 1.2
- SageMaker client follows AWS integration patterns from DevAgent plugin
- Database models extend established data model conventions
- API endpoints follow existing routing and versioning patterns

**No Breaking Changes:** This story extends existing functionality without modifying core kernel or plugin interfaces established in previous stories.

### Testing

**Testing Framework:**
- **Unit Tests**: `tests/unit/test_services/test_code_search.py` using pytest with mocking
- **Integration Tests**: `tests/integration/test_database/test_vector_search.py` for database operations
- **Mock Strategy**: Mock SageMaker responses for unit tests, test database for integration
- **Coverage Target:** Minimum 80% code coverage for indexing and search functionality

**Specific Testing Requirements for This Story:**
- File discovery accuracy with proper exclusion handling
- BGE-M3 embedding generation with batch processing validation
- Vector storage integrity with pgvector similarity search
- Search relevance with top-5 results ranking validation
- 80%+ indexing coverage requirement validation
- Performance testing for large codebases (1000+ files)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2024-01-15 | 1.0 | Initial story creation with comprehensive vector search and BGE-M3 integration context | Scrum Master |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results

*This section will be populated by the QA agent after story completion*